{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "import gradio as gr\n",
    "from datetime import timedelta\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions \n",
    "def analyze_tweets(tweets):\n",
    "    #delimiter \n",
    "    tweet_list = tweets.split('|||')\n",
    "       \n",
    "    compound_scores = [sid.polarity_scores(tweet.strip())['compound'] for tweet in tweet_list if tweet.strip()]\n",
    "       \n",
    "    if compound_scores:\n",
    "        average_sentiment = sum(compound_scores) / len(compound_scores)\n",
    "    else:\n",
    "        return \"No  tweets entered.\"\n",
    "    \n",
    "    return f\"The average compound sentiment score for the entered tweets is: {average_sentiment}\"\n",
    "\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        past_60_days = data[i-seq_length:i, 0]\n",
    "        current_features = data[i, [1, 2, 3]]\n",
    "        sequence = np.concatenate((past_60_days, current_features), axis=0)\n",
    "        sequences.append(sequence)\n",
    "        labels.append(data[i, 0])\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "def fetch_recent_stock_data(stock_symbol, period='3mo'):\n",
    "    stock_data = yf.download(stock_symbol, period=period)\n",
    "    if stock_data.empty:\n",
    "        raise ValueError(f\"No data found for {stock_symbol}.\")\n",
    "    return stock_data\n",
    "\n",
    "#close prediction and caculate dates\n",
    "def predict_next_day_close_yfinance(stock_symbol, sentiment_score, number_of_tweets):\n",
    "    stock_data = fetch_recent_stock_data(stock_symbol)\n",
    "    if len(stock_data) < 60:\n",
    "        raise ValueError(f\"Not enough data available for {stock_symbol}.\")\n",
    "    \n",
    "    past_60_days_close = stock_data['Close'][-60:].values\n",
    "    most_recent_data = stock_data.iloc[-1]\n",
    "    open_price = most_recent_data['Open']\n",
    "    \n",
    "    past_60_days_scaled = scaler.transform(np.column_stack((past_60_days_close, np.zeros((60, 3)))))[0:60, 0]\n",
    "    current_features_scaled = scaler.transform([[0, sentiment_score, number_of_tweets, open_price]])[0, 1:]\n",
    "    \n",
    "    input_sequence = np.concatenate((past_60_days_scaled, current_features_scaled), axis=0)\n",
    "    input_sequence = np.reshape(input_sequence, (1, 1, len(input_sequence)))\n",
    "    \n",
    "    predicted_price_scaled = model.predict(input_sequence)\n",
    "    predicted_price = scaler.inverse_transform([[predicted_price_scaled[0][0], 0, 0, 0]])[0][0]\n",
    "\n",
    "    #calculate the next trading day\n",
    "    latest_date = stock_data.index[-1]\n",
    "    next_prediction_date = latest_date + timedelta(days=1)\n",
    "    \n",
    "    return predicted_price, next_prediction_date\n",
    "\n",
    "#train model on selected stock\n",
    "def train_model(stock_symbol):\n",
    "    stock_specific_data = merged_data[merged_data['Stock Name'] == stock_symbol].sort_values(by='Date')\n",
    "    \n",
    "    \n",
    "    training_columns = ['Close', 'Average_Sentiment', 'Number_of_Tweets', 'Open']\n",
    "    training_data = stock_specific_data[training_columns].dropna()\n",
    "\n",
    "    #scaling\n",
    "    global scaler #global to be used across functions\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_training_data = scaler.fit_transform(training_data)\n",
    "\n",
    "    #sequences\n",
    "    sequence_length = 60\n",
    "    X_train, y_train = create_sequences(scaled_training_data, sequence_length)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "\n",
    "   \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    #LSTM\n",
    "    global model #global to be used across functions\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=25))\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x_train, y_train, batch_size=1, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "    return f\"Model trained on {stock_symbol}.\"\n",
    "\n",
    "\n",
    "def predict_stock_price(stock_symbol, sentiment_score, number_of_tweets):\n",
    "    \n",
    "    train_message = train_model(stock_symbol)\n",
    "    \n",
    "    \n",
    "    predicted_price, prediction_date = predict_next_day_close_yfinance(stock_symbol, sentiment_score, number_of_tweets)\n",
    "    \n",
    "    return f\"{train_message}\\nThe predicted closing price for {stock_symbol} on {prediction_date.date()} is: {predicted_price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['Stock Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file \n",
    "file_path = 'merged_sentiment_stock_data.csv'\n",
    "merged_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7878/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stock tab\n",
    "stock_price_tab = gr.Interface(\n",
    "    fn=predict_stock_price,\n",
    "    inputs=[\n",
    "        gr.Dropdown(label=\"Stock Symbol\", choices=['AAPL', 'AMD', 'AMZN', 'DIS', 'GOOG', 'META', 'MSFT', 'NFLX',\n",
    "       'NIO', 'PG', 'TSLA', 'TSM', 'XPEV', 'CRM', 'ZS', 'ENPH', 'PYPL',\n",
    "       'BA', 'COST', 'KO', 'BX', 'F', 'INTC', 'NOC', 'VZ'], value=\"AAPL\"),\n",
    "        gr.Slider(minimum=-1.0, maximum=1.0, value=0.4, label=\"Sentiment Score\"),\n",
    "        gr.Slider(minimum=0, maximum=350, value=50, label=\"Number of Tweets\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Stock Price Prediction\",\n",
    "    description=\"Train the model on the selected stock symbol and predict the next day's closing price.\"\n",
    ")\n",
    "#sentiment tab\n",
    "sentiment_tab = gr.Interface(\n",
    "    fn=analyze_tweets,\n",
    "    inputs=gr.Textbox(\n",
    "        lines=5,\n",
    "        placeholder=\"Enter multiple tweets separated by '|||'\",\n",
    "        label=\"Tweets\"\n",
    "    ),\n",
    "    outputs=\"text\",\n",
    "    title=\"Tweet Sentiment Analysis\",\n",
    "    description=\"Enter multiple tweets separated by '|||', and get the average compound sentiment score.\"\n",
    ")\n",
    "\n",
    "#tabbed interface \n",
    "app = gr.TabbedInterface([stock_price_tab, sentiment_tab], tab_names=[\"Stock Price Prediction\", \"Tweet Sentiment Analysis\"])\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
